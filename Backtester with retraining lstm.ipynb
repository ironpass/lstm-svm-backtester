{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Input, merge, Flatten, Lambda, concatenate, Bidirectional, LSTM, Reshape\n",
    "from keras.optimizers import SGD,Adam, Adadelta\n",
    "from keras.models import load_model\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = Input(shape=(10,4))\n",
    "\n",
    "    output = LSTM(4, return_sequences=False)(input_layer)\n",
    "\n",
    "    output = Dense(2, activation=\"softmax\")(output)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    optimizer = Adam(0.001) \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def retrain(training_set, target):\n",
    "    model = create_model()\n",
    "    \n",
    "    model.fit(np.array(training_set), np.array(target), epochs=200, validation_split=0.2, verbose=2)\n",
    "    print(\"Retraining....\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(testing_hourly, backtest_params):\n",
    "    params = {\n",
    "        \"balance\":1000,\n",
    "        \"volume\": backtest_params[\"volume\"]*10000, #10,000 == 1 lot\n",
    "        \"tp\": backtest_params[\"tp\"], # 400 pips\n",
    "        \"sl\": backtest_params[\"sl\"], # 400 pips\n",
    "\n",
    "        \"hour_counter\":0,\n",
    "        \"day_count\":0,\n",
    "        \"today_positions\":[],\n",
    "        \"model_inputs\":[[0,0,0,0]],\n",
    "\n",
    "        \"polarity\":0,\n",
    "        \"tp_boundary\":0,\n",
    "        \"sl_boundary\":0,\n",
    "        \n",
    "        \"latest_date\":testing_hourly[\"<DATE>\"][0],\n",
    "        \"minimum_training_set\":1411,\n",
    "        \"is_retrain\":backtest_params[\"is_retrain\"],\n",
    "        \"retrain_interval\":200\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def close_order(order):\n",
    "    order[\"open_position\"]=None\n",
    "    order[\"age\"] = 0\n",
    "    order[\"type\"] = None\n",
    "    order[\"tp_pos\"] = None\n",
    "    order[\"sl_pos\"] = None\n",
    "    order[\"close_status\"] = None\n",
    "    order[\"opening_time\"] = None\n",
    "    order[\"closing_time\"] = None\n",
    "\n",
    "def is_there_an_order(order):\n",
    "    if(order[\"open_position\"]!=None):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def order_aging(order):\n",
    "    if(is_there_an_order(order)):\n",
    "        order[\"age\"]+=1\n",
    "\n",
    "def calculateMargin(open_position, close_position, order_type, order_volume):\n",
    "    if (order_type == \"BUY\"):\n",
    "        return (close_position - open_position) * order_volume\n",
    "    elif(order_type == \"SELL\"):\n",
    "        return (open_position - close_position) * order_volume\n",
    "    return 0\n",
    "\n",
    "def hourly_to_daily(today_positions):\n",
    "    today_open = today_positions[0][0]\n",
    "    today_high = np.max(today_positions) \n",
    "    today_low = np.min(today_positions)\n",
    "    today_close = today_positions[-1][3]\n",
    "    return [today_open, today_high, today_low, today_close]\n",
    "\n",
    "def update(params, record):\n",
    "    if(record[\"<DATE>\"] != params[\"latest_date\"]):\n",
    "        params[\"day_count\"] += 1\n",
    "        params[\"hour_counter\"] = 0\n",
    "        params[\"model_inputs\"].append(hourly_to_daily(params[\"today_positions\"]))\n",
    "        params[\"today_positions\"] = []\n",
    "        \n",
    "    params[\"today_positions\"].append([record[\"<OPEN>\"], record[\"<HIGH>\"], record[\"<LOW>\"], record[\"<CLOSE>\"]])\n",
    "    params[\"hour_counter\"]+=1\n",
    "\n",
    "        \n",
    "def scale_diff(next_val, curr_val):\n",
    "    scaled_diff = min(1, next_val-curr_val)\n",
    "    scaled_diff = max(-1, scaled_diff)\n",
    "    return scaled_diff\n",
    "\n",
    "def find_diff(model_inputs):\n",
    "    diff_model_inputs = []\n",
    "    for i in range(len(model_inputs[:-1])):\n",
    "        curr_record = model_inputs[i]\n",
    "        next_record = model_inputs[i+1]\n",
    "        \n",
    "        open_diff = scale_diff(next_record[0], curr_record[0])\n",
    "        high_diff = scale_diff(next_record[1], curr_record[1])\n",
    "        low_diff = scale_diff(next_record[2], curr_record[2])\n",
    "        close_diff = scale_diff(next_record[3], curr_record[3])\n",
    "        \n",
    "        diff_model_inputs.append([open_diff,high_diff,low_diff,close_diff])\n",
    "    return diff_model_inputs\n",
    "\n",
    "\n",
    "def update_volume(balance, avg_swing, static_scale):\n",
    "    return ((balance * 0.1) / avg_swing) * static_scale\n",
    "\n",
    "def update_model_inputs(diff_model_inputs, retrain_input, retrain_target):\n",
    "    if(len(retrain_input) >= 1401):\n",
    "        del retrain_input[:1]\n",
    "        \n",
    "    retrain_input.append(diff_model_inputs)\n",
    "    \n",
    "    if(len(retrain_input) > 1):\n",
    "        if(len(retrain_target) >= 1400):\n",
    "            del retrain_target[:1]\n",
    "        retrain_target.append(find_target_for_retrain(diff_model_inputs[-1]))\n",
    "\n",
    "def find_target_for_retrain(diff_model_input):    \n",
    "    if(diff_model_input[1] >= -1*diff_model_input[2]):\n",
    "        return [0,1]\n",
    "    else:\n",
    "        return [1,0]\n",
    "        \n",
    "def ask_model_for_signal(model, params, record, order_signal, retrain_input, retrain_target):\n",
    "    diff_model_inputs = find_diff(params[\"model_inputs\"])\n",
    "    if(len(params[\"model_inputs\"])>=11 and params[\"day_count\"] >= params[\"minimum_training_set\"]):\n",
    "        if(params[\"day_count\"] >= params[\"minimum_training_set\"] and (params[\"day_count\"]-11) % params[\"retrain_interval\"] == 0 ):\n",
    "            if(params[\"is_retrain\"] == \"always\"):\n",
    "                model = retrain(retrain_input[:-1], retrain_target)\n",
    "            elif(params[\"is_retrain\"] == \"once\"):\n",
    "                model = retrain(retrain_input[:-1], retrain_target)\n",
    "                params[\"is_retrain\"] = \"trained\"\n",
    "        \n",
    "        order_signal = model.predict(np.expand_dims(np.array(diff_model_inputs), axis=0))[0]\n",
    "        params[\"model_inputs\"] = params[\"model_inputs\"][1:]\n",
    "\n",
    "        update_model_inputs(diff_model_inputs, retrain_input, retrain_target)\n",
    "        \n",
    "        \n",
    "\n",
    "    elif(len(params[\"model_inputs\"])>=11):\n",
    "        params[\"latest_date\"] = record[\"<DATE>\"]\n",
    "        params[\"model_inputs\"] = params[\"model_inputs\"][1:]\n",
    "        \n",
    "        update_model_inputs(diff_model_inputs, retrain_input, retrain_target)\n",
    "    else:\n",
    "        params[\"latest_date\"] = record[\"<DATE>\"]\n",
    "\n",
    "    return order_signal, model\n",
    "    \n",
    "def should_order_be_closed(order, params, record, order_history):\n",
    "    close_order_event = {}\n",
    "    if(order[\"type\"]==\"BUY\"):\n",
    "        params[\"polarity\"] = 1\n",
    "        params[\"tp_boundary\"] = record[\"<HIGH>\"]\n",
    "        params[\"sl_boundary\"] = record[\"<LOW>\"]\n",
    "    elif(order[\"type\"]==\"SELL\"):\n",
    "        params[\"polarity\"] = -1\n",
    "        params[\"tp_boundary\"] = record[\"<LOW>\"]\n",
    "        params[\"sl_boundary\"] = record[\"<HIGH>\"]\n",
    "        \n",
    "    if(is_there_an_order(order)):\n",
    "        profit = 0\n",
    "        closing_position = 0\n",
    "        if(params[\"sl_boundary\"]*params[\"polarity\"] <= order[\"sl_pos\"]*params[\"polarity\"]):\n",
    "            profit = calculateMargin(order[\"open_position\"], order[\"sl_pos\"], order[\"type\"], params[\"volume\"])\n",
    "            params[\"balance\"] += profit\n",
    "            order[\"close_status\"] = \"sl\"\n",
    "            order[\"closing_time\"] = record[\"<DATE>\"]+\"-\"+record[\"<TIME>\"]\n",
    "            closing_position = order[\"sl_pos\"]\n",
    "        elif(params[\"tp_boundary\"]*params[\"polarity\"] >= order[\"tp_pos\"]*params[\"polarity\"]):\n",
    "            profit = calculateMargin(order[\"open_position\"], order[\"tp_pos\"], order[\"type\"], params[\"volume\"])\n",
    "            params[\"balance\"] += profit\n",
    "            order[\"close_status\"] = \"tp\"\n",
    "            order[\"closing_time\"] = record[\"<DATE>\"]+\"-\"+record[\"<TIME>\"]\n",
    "            closing_position = order[\"tp_pos\"]\n",
    "        # In case neither sl or tp is reached, the order will be closed at the end of the day\n",
    "        elif (record[\"<DATE>\"] != params[\"latest_date\"]):\n",
    "            profit =  calculateMargin(order[\"open_position\"], record[\"<OPEN>\"], order[\"type\"], params[\"volume\"])\n",
    "            params[\"balance\"] += profit\n",
    "            order[\"close_status\"] = \"eotd\"\n",
    "            order[\"closing_time\"] = record[\"<DATE>\"]+\"-\"+record[\"<TIME>\"]\n",
    "            closing_position = record[\"<CLOSE>\"]\n",
    "            \n",
    "        if(not order[\"close_status\"] is None):\n",
    "            order_history.append(order.copy())\n",
    "            close_order(order)\n",
    "            \n",
    "            close_order_event = {\n",
    "                \"closing_position\":closing_position,\n",
    "                \"profit\":profit,\n",
    "                \"datetime\":record[\"<DATE>\"]\n",
    "            }\n",
    "    return close_order_event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(testing_hourly, model, backtest_params):\n",
    "    order = {\n",
    "        \"open_position\":None,\n",
    "        \"age\":0,\n",
    "        \"type\":None,\n",
    "        \"tp_pos\":None,\n",
    "        \"sl_pos\":None,\n",
    "        \"close_status\":None,\n",
    "        \"opening_time\":None,\n",
    "        \"closing_time\":None\n",
    "    }\n",
    "    \n",
    "    params = init_params(testing_hourly, backtest_params)\n",
    "    \n",
    "    balance_history = [params[\"balance\"]]\n",
    "    order_history = []\n",
    "    order_signal = None\n",
    "    \n",
    "    retrain_input = []\n",
    "    retrain_target = []\n",
    "    \n",
    "    open_order_events = []\n",
    "    close_order_events = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for idx, record in tqdm(testing_hourly[:-1].iterrows()):\n",
    "        \n",
    "        open_order_event = {}\n",
    "        close_order_event = {}\n",
    "    \n",
    "        # Update params hourly\n",
    "        update(params, record)\n",
    "\n",
    "        # Call the model for a signal\n",
    "        order_signal, model = ask_model_for_signal(model, params, record, order_signal, retrain_input, retrain_target)\n",
    "\n",
    "        # Check whether sl or tp is reached\n",
    "        close_order_event = should_order_be_closed(order, params, record, order_history)\n",
    "\n",
    "        # Open an order\n",
    "        if(not order_signal is None):\n",
    "            if ((not is_there_an_order(order)) and (record[\"<DATE>\"] != params[\"latest_date\"])):\n",
    "                order[\"opening_time\"] = record[\"<DATE>\"]+\"-\"+record[\"<TIME>\"]\n",
    "                order[\"open_position\"] = record[\"<OPEN>\"]       \n",
    "                # Classification Model Logic\n",
    "                if(np.argmax(order_signal) == 0):\n",
    "                    order[\"type\"] = \"SELL\"\n",
    "                elif(np.argmax(order_signal) == 1):\n",
    "                    order[\"type\"] = \"BUY\"\n",
    "                else:\n",
    "                    order[\"type\"] = None\n",
    "\n",
    "                order[\"tp_pos\"] = order[\"open_position\"]+params[\"tp\"] if order[\"type\"]==\"BUY\" else order[\"open_position\"]-params[\"tp\"]\n",
    "                order[\"sl_pos\"] = order[\"open_position\"]-params[\"sl\"] if order[\"type\"]==\"BUY\" else order[\"open_position\"]+params[\"sl\"]\n",
    "                \n",
    "                \n",
    "                open_order_event = {\n",
    "                    \"open_position\":order[\"open_position\"],\n",
    "                    \"order_type\":order[\"type\"],\n",
    "                    \"volume\":params[\"volume\"],\n",
    "                    \"datetime\":record[\"<DATE>\"]\n",
    "                }\n",
    "                \n",
    "            params[\"latest_date\"] = record[\"<DATE>\"]\n",
    "        \n",
    "        balance_history.append(params[\"balance\"])\n",
    "\n",
    "        # Let the order ages\n",
    "        order_aging(order)\n",
    "        \n",
    "        open_order_events.append(open_order_event)\n",
    "        close_order_events.append(close_order_event)\n",
    "    \n",
    "    open_order_events.append({})\n",
    "    close_order_events.append({})\n",
    "    \n",
    "    graph = pd.DataFrame({\n",
    "        \"date\":testing_hourly[\"<DATE>\"],\n",
    "        \"open\":testing_hourly[\"<OPEN>\"],\n",
    "        \"high\":testing_hourly[\"<HIGH>\"],\n",
    "        \"low\":testing_hourly[\"<LOW>\"],\n",
    "        \"close\":testing_hourly[\"<CLOSE>\"],\n",
    "        \"volume\":testing_hourly[\"<TICKVOL>\"],\n",
    "        \"balance_history\":balance_history,\n",
    "        \"open_order_events\":open_order_events,\n",
    "        \"close_order_events\":close_order_events\n",
    "    })\n",
    "    K.clear_session()\n",
    "\n",
    "    return graph.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32917it [00:04, 6586.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6935 - val_loss: 0.6933\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6932 - val_loss: 0.6930\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6932 - val_loss: 0.6930\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6932 - val_loss: 0.6929\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6932 - val_loss: 0.6928\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6931 - val_loss: 0.6929\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6930 - val_loss: 0.6927\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6930 - val_loss: 0.6928\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6929 - val_loss: 0.6929\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6929 - val_loss: 0.6925\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6926 - val_loss: 0.6925\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6924 - val_loss: 0.6923\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6922 - val_loss: 0.6919\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6919 - val_loss: 0.6918\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6916 - val_loss: 0.6910\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6911 - val_loss: 0.6910\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6905 - val_loss: 0.6898\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6900 - val_loss: 0.6891\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6889 - val_loss: 0.6884\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6878 - val_loss: 0.6872\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6865 - val_loss: 0.6858\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6849 - val_loss: 0.6841\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6829 - val_loss: 0.6819\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6805 - val_loss: 0.6782\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6765 - val_loss: 0.6754\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6731 - val_loss: 0.6752\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6711 - val_loss: 0.6731\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6692 - val_loss: 0.6715\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6673 - val_loss: 0.6702\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6657 - val_loss: 0.6693\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6648 - val_loss: 0.6685\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6635 - val_loss: 0.6657\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.6624 - val_loss: 0.6649\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.6618 - val_loss: 0.6639\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.6599 - val_loss: 0.6630\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.6598 - val_loss: 0.6606\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.6589 - val_loss: 0.6610\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.6574 - val_loss: 0.6583\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.6557 - val_loss: 0.6577\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.6550 - val_loss: 0.6562\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.6542 - val_loss: 0.6561\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6533 - val_loss: 0.6542\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6527 - val_loss: 0.6530\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6518 - val_loss: 0.6527\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6511 - val_loss: 0.6500\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6490 - val_loss: 0.6502\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6487 - val_loss: 0.6482\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6477 - val_loss: 0.6468\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6469 - val_loss: 0.6465\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6460 - val_loss: 0.6452\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6453 - val_loss: 0.6449\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6455 - val_loss: 0.6444\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6438 - val_loss: 0.6425\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6434 - val_loss: 0.6409\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6422 - val_loss: 0.6400\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6415 - val_loss: 0.6392\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6404 - val_loss: 0.6378\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6400 - val_loss: 0.6375\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6398 - val_loss: 0.6363\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6387 - val_loss: 0.6356\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6386 - val_loss: 0.6353\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6382 - val_loss: 0.6336\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6376 - val_loss: 0.6327\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6363 - val_loss: 0.6321\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6357 - val_loss: 0.6314\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6349 - val_loss: 0.6305\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6342 - val_loss: 0.6295\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6337 - val_loss: 0.6281\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6329 - val_loss: 0.6276\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6323 - val_loss: 0.6265\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6320 - val_loss: 0.6266\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6310 - val_loss: 0.6254\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6308 - val_loss: 0.6241\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6302 - val_loss: 0.6238\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6297 - val_loss: 0.6222\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6287 - val_loss: 0.6222\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6296 - val_loss: 0.6208\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6278 - val_loss: 0.6210\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6272 - val_loss: 0.6201\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6273 - val_loss: 0.6191\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6278 - val_loss: 0.6194\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6259 - val_loss: 0.6181\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6254 - val_loss: 0.6168\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6248 - val_loss: 0.6174\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6253 - val_loss: 0.6156\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6234 - val_loss: 0.6177\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6236 - val_loss: 0.6149\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6233 - val_loss: 0.6146\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32917it [00:20, 1644.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6226 - val_loss: 0.6142\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6225 - val_loss: 0.6141\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6215 - val_loss: 0.6120\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6219 - val_loss: 0.6121\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6208 - val_loss: 0.6116\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6211 - val_loss: 0.6113\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6204 - val_loss: 0.6105\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6196 - val_loss: 0.6101\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6201 - val_loss: 0.6109\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6197 - val_loss: 0.6086\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6189 - val_loss: 0.6082\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6189 - val_loss: 0.6092\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6186 - val_loss: 0.6077\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6174 - val_loss: 0.6068\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6173 - val_loss: 0.6062\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6173 - val_loss: 0.6053\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6165 - val_loss: 0.6051\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6163 - val_loss: 0.6050\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6165 - val_loss: 0.6049\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6157 - val_loss: 0.6051\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6150 - val_loss: 0.6043\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6153 - val_loss: 0.6037\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6148 - val_loss: 0.6031\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6145 - val_loss: 0.6015\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6138 - val_loss: 0.6013\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6139 - val_loss: 0.6010\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6137 - val_loss: 0.6037\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6124 - val_loss: 0.6003\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.6124 - val_loss: 0.6009\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.6124 - val_loss: 0.6005\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.6127 - val_loss: 0.5995\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.6117 - val_loss: 0.6006\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.6119 - val_loss: 0.5986\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.6110 - val_loss: 0.5983\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.6105 - val_loss: 0.5979\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.6102 - val_loss: 0.5977\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.6105 - val_loss: 0.5969\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.6095 - val_loss: 0.5972\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.6091 - val_loss: 0.5967\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.6089 - val_loss: 0.5963\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.6088 - val_loss: 0.5959\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.6084 - val_loss: 0.5954\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.6093 - val_loss: 0.5951\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.6084 - val_loss: 0.5960\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.6076 - val_loss: 0.5941\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6069 - val_loss: 0.5945\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.6069 - val_loss: 0.5942\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.6066 - val_loss: 0.5932\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.6065 - val_loss: 0.5939\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6060 - val_loss: 0.5925\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6058 - val_loss: 0.5933\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.6055 - val_loss: 0.5919\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.6056 - val_loss: 0.5942\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.6048 - val_loss: 0.5922\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.6046 - val_loss: 0.5911\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.6048 - val_loss: 0.5923\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.6035 - val_loss: 0.5907\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.6040 - val_loss: 0.5901\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.6038 - val_loss: 0.5911\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.6034 - val_loss: 0.5903\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.6028 - val_loss: 0.5897\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.6028 - val_loss: 0.5898\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.6026 - val_loss: 0.5894\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.6021 - val_loss: 0.5897\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.6019 - val_loss: 0.5887\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.6017 - val_loss: 0.5883\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.6016 - val_loss: 0.5882\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.6020 - val_loss: 0.5892\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.6009 - val_loss: 0.5884\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.6006 - val_loss: 0.5874\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.6011 - val_loss: 0.5878\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.6001 - val_loss: 0.5874\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.6002 - val_loss: 0.5882\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.6000 - val_loss: 0.5861\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5995 - val_loss: 0.5860\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.6001 - val_loss: 0.5858\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5991 - val_loss: 0.5862\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.6003 - val_loss: 0.5854\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5983 - val_loss: 0.5867\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5999 - val_loss: 0.5878\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.5984 - val_loss: 0.5854\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5980 - val_loss: 0.5846\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5991 - val_loss: 0.5861\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5986 - val_loss: 0.5840\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5981 - val_loss: 0.5840\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.5981 - val_loss: 0.5858\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.5963 - val_loss: 0.5837\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.5962 - val_loss: 0.5841\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.5963 - val_loss: 0.5836\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.5956 - val_loss: 0.5833\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.5957 - val_loss: 0.5834\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.5956 - val_loss: 0.5840\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.5955 - val_loss: 0.5835\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.5951 - val_loss: 0.5839\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.5961 - val_loss: 0.5831\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.5947 - val_loss: 0.5819\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.5944 - val_loss: 0.5832\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.5940 - val_loss: 0.5825\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.5936 - val_loss: 0.5821\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.5946 - val_loss: 0.5822\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.5933 - val_loss: 0.5827\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.5932 - val_loss: 0.5824\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.5926 - val_loss: 0.5810\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5925 - val_loss: 0.5823\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5928 - val_loss: 0.5816\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.5818\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5923 - val_loss: 0.5818\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.5803\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5916 - val_loss: 0.5804\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5911 - val_loss: 0.5816\n",
      "Retraining....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38157it [00:37, 1025.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6933 - val_loss: 0.6941\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6934 - val_loss: 0.6949\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6932 - val_loss: 0.6942\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6931 - val_loss: 0.6941\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6931 - val_loss: 0.6947\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6930 - val_loss: 0.6946\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6929 - val_loss: 0.6949\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6929 - val_loss: 0.6947\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6928 - val_loss: 0.6950\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6927 - val_loss: 0.6946\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6927 - val_loss: 0.6945\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6925 - val_loss: 0.6942\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6923 - val_loss: 0.6942\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6921 - val_loss: 0.6936\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6919 - val_loss: 0.6942\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6916 - val_loss: 0.6933\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6914 - val_loss: 0.6929\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6909 - val_loss: 0.6921\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6905 - val_loss: 0.6921\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6900 - val_loss: 0.6913\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6895 - val_loss: 0.6911\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6894 - val_loss: 0.6909\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6885 - val_loss: 0.6881\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6874 - val_loss: 0.6880\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6866 - val_loss: 0.6864\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6856 - val_loss: 0.6865\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6846 - val_loss: 0.6848\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6833 - val_loss: 0.6827\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6819 - val_loss: 0.6796\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6802 - val_loss: 0.6784\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6784 - val_loss: 0.6753\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6756 - val_loss: 0.6733\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6750 - val_loss: 0.6708\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6733 - val_loss: 0.6715\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.6724 - val_loss: 0.6721\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.6706 - val_loss: 0.6663\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.6698 - val_loss: 0.6652\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.6688 - val_loss: 0.6658\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.6679 - val_loss: 0.6635\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.6671 - val_loss: 0.6634\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.6670 - val_loss: 0.6639\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.6647 - val_loss: 0.6592\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.6651 - val_loss: 0.6589\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6638 - val_loss: 0.6583\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6625 - val_loss: 0.6560\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6617 - val_loss: 0.6544\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6611 - val_loss: 0.6520\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6598 - val_loss: 0.6534\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6589 - val_loss: 0.6518\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6584 - val_loss: 0.6517\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6578 - val_loss: 0.6506\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6564 - val_loss: 0.6482\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6559 - val_loss: 0.6488\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6550 - val_loss: 0.6464\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6549 - val_loss: 0.6461\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6537 - val_loss: 0.6437\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6532 - val_loss: 0.6435\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6524 - val_loss: 0.6458\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6513 - val_loss: 0.6426\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6509 - val_loss: 0.6404\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6500 - val_loss: 0.6388\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6501 - val_loss: 0.6398\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6488 - val_loss: 0.6367\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6483 - val_loss: 0.6377\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6475 - val_loss: 0.6370\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6470 - val_loss: 0.6340\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6460 - val_loss: 0.6358\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6454 - val_loss: 0.6330\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6449 - val_loss: 0.6336\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6443 - val_loss: 0.6318\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6435 - val_loss: 0.6304\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6429 - val_loss: 0.6288\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6431 - val_loss: 0.6294\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38157it [00:50, 762.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6419 - val_loss: 0.6269\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6410 - val_loss: 0.6268\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6403 - val_loss: 0.6277\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6400 - val_loss: 0.6252\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6393 - val_loss: 0.6257\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6386 - val_loss: 0.6260\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6386 - val_loss: 0.6256\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6377 - val_loss: 0.6233\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6374 - val_loss: 0.6206\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6365 - val_loss: 0.6221\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6360 - val_loss: 0.6193\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6355 - val_loss: 0.6204\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6348 - val_loss: 0.6187\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6343 - val_loss: 0.6182\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6335 - val_loss: 0.6179\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6331 - val_loss: 0.6165\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6324 - val_loss: 0.6150\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.6320 - val_loss: 0.6169\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6315 - val_loss: 0.6145\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6314 - val_loss: 0.6135\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6308 - val_loss: 0.6127\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6298 - val_loss: 0.6117\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6296 - val_loss: 0.6118\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6293 - val_loss: 0.6098\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6284 - val_loss: 0.6109\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6285 - val_loss: 0.6086\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6279 - val_loss: 0.6100\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6270 - val_loss: 0.6074\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6269 - val_loss: 0.6073\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6264 - val_loss: 0.6067\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6260 - val_loss: 0.6077\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6257 - val_loss: 0.6040\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6250 - val_loss: 0.6054\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6246 - val_loss: 0.6035\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6243 - val_loss: 0.6051\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6238 - val_loss: 0.6011\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6238 - val_loss: 0.6041\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6230 - val_loss: 0.6004\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6221 - val_loss: 0.6012\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6224 - val_loss: 0.6014\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6213 - val_loss: 0.6005\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6213 - val_loss: 0.5992\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6208 - val_loss: 0.6007\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6205 - val_loss: 0.5989\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6199 - val_loss: 0.5972\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.6195 - val_loss: 0.5973\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.6195 - val_loss: 0.5980\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.6188 - val_loss: 0.5957\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.6184 - val_loss: 0.5951\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.6182 - val_loss: 0.5947\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.6177 - val_loss: 0.5939\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.6179 - val_loss: 0.5943\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.6172 - val_loss: 0.5935\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.6169 - val_loss: 0.5924\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.6168 - val_loss: 0.5904\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.6164 - val_loss: 0.5905\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.6164 - val_loss: 0.5933\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.6154 - val_loss: 0.5903\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.6148 - val_loss: 0.5903\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.6152 - val_loss: 0.5919\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.6148 - val_loss: 0.5881\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.6144 - val_loss: 0.5873\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6147 - val_loss: 0.5877\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.6137 - val_loss: 0.5865\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.6133 - val_loss: 0.5862\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.6127 - val_loss: 0.5881\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6127 - val_loss: 0.5894\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6123 - val_loss: 0.5860\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.6120 - val_loss: 0.5841\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.6116 - val_loss: 0.5854\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.6128 - val_loss: 0.5827\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.6106 - val_loss: 0.5870\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.6116 - val_loss: 0.5841\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.6106 - val_loss: 0.5838\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.6112 - val_loss: 0.5846\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.6110 - val_loss: 0.5821\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.6107 - val_loss: 0.5812\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.6098 - val_loss: 0.5805\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.6095 - val_loss: 0.5808\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.6089 - val_loss: 0.5826\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.6091 - val_loss: 0.5814\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.6085 - val_loss: 0.5807\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.6082 - val_loss: 0.5805\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.6077 - val_loss: 0.5780\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.6077 - val_loss: 0.5793\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.6077 - val_loss: 0.5795\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.6071 - val_loss: 0.5782\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.6068 - val_loss: 0.5776\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.6069 - val_loss: 0.5775\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.6065 - val_loss: 0.5766\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.6062 - val_loss: 0.5768\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.6068 - val_loss: 0.5765\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.6065 - val_loss: 0.5766\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.6058 - val_loss: 0.5761\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.6054 - val_loss: 0.5756\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.6056 - val_loss: 0.5749\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.6057 - val_loss: 0.5737\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.6050 - val_loss: 0.5752\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.6041 - val_loss: 0.5757\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.6041 - val_loss: 0.5746\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.6037 - val_loss: 0.5740\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.6040 - val_loss: 0.5731\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.6032 - val_loss: 0.5727\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.6032 - val_loss: 0.5740\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.6028 - val_loss: 0.5716\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.6028 - val_loss: 0.5732\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.6023 - val_loss: 0.5733\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.6020 - val_loss: 0.5705\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.6021 - val_loss: 0.5712\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.6016 - val_loss: 0.5705\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.6028 - val_loss: 0.5741\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.6017 - val_loss: 0.5694\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.6011 - val_loss: 0.5713\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.6018 - val_loss: 0.5680\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.6008 - val_loss: 0.5695\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.6007 - val_loss: 0.5705\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.6005 - val_loss: 0.5712\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.6003 - val_loss: 0.5695\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.6002 - val_loss: 0.5684\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.6001 - val_loss: 0.5685\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5995 - val_loss: 0.5672\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5996 - val_loss: 0.5684\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5990 - val_loss: 0.5666\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5988 - val_loss: 0.5673\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5987 - val_loss: 0.5679\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5984 - val_loss: 0.5658\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5984 - val_loss: 0.5667\n",
      "Retraining....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42724it [01:10, 610.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6932 - val_loss: 0.6931\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6926 - val_loss: 0.6925\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6927 - val_loss: 0.6918\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6922 - val_loss: 0.6922\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6921 - val_loss: 0.6914\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6920 - val_loss: 0.6910\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6917 - val_loss: 0.6915\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6912 - val_loss: 0.6906\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6911 - val_loss: 0.6905\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6908 - val_loss: 0.6906\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6900 - val_loss: 0.6894\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6897 - val_loss: 0.6891\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6891 - val_loss: 0.6884\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6886 - val_loss: 0.6889\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6878 - val_loss: 0.6872\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6869 - val_loss: 0.6867\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6861 - val_loss: 0.6857\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6854 - val_loss: 0.6853\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6843 - val_loss: 0.6838\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6828 - val_loss: 0.6826\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6813 - val_loss: 0.6803\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6792 - val_loss: 0.6802\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6772 - val_loss: 0.6761\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6748 - val_loss: 0.6744\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6716 - val_loss: 0.6713\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6676 - val_loss: 0.6661\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6653 - val_loss: 0.6649\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6632 - val_loss: 0.6634\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6623 - val_loss: 0.6621\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6602 - val_loss: 0.6591\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6581 - val_loss: 0.6579\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6572 - val_loss: 0.6560\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.6553 - val_loss: 0.6554\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.6540 - val_loss: 0.6544\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.6530 - val_loss: 0.6527\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.6518 - val_loss: 0.6516\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.6503 - val_loss: 0.6515\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.6491 - val_loss: 0.6504\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.6485 - val_loss: 0.6479\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.6475 - val_loss: 0.6474\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.6463 - val_loss: 0.6475\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6466 - val_loss: 0.6479\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6449 - val_loss: 0.6442\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6432 - val_loss: 0.6432\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6417 - val_loss: 0.6432\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6409 - val_loss: 0.6435\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6402 - val_loss: 0.6420\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6390 - val_loss: 0.6416\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6381 - val_loss: 0.6397\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6375 - val_loss: 0.6392\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6360 - val_loss: 0.6382\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6351 - val_loss: 0.6369\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6347 - val_loss: 0.6378\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42724it [01:20, 533.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6333 - val_loss: 0.6355\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6334 - val_loss: 0.6337\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6317 - val_loss: 0.6353\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6312 - val_loss: 0.6339\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6298 - val_loss: 0.6343\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6293 - val_loss: 0.6316\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6281 - val_loss: 0.6318\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6275 - val_loss: 0.6307\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6265 - val_loss: 0.6295\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6259 - val_loss: 0.6284\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6251 - val_loss: 0.6302\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6243 - val_loss: 0.6279\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6246 - val_loss: 0.6275\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6226 - val_loss: 0.6282\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6224 - val_loss: 0.6269\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6214 - val_loss: 0.6245\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6205 - val_loss: 0.6252\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6210 - val_loss: 0.6234\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6196 - val_loss: 0.6252\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6196 - val_loss: 0.6254\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6188 - val_loss: 0.6245\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6171 - val_loss: 0.6218\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6167 - val_loss: 0.6208\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6160 - val_loss: 0.6215\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6156 - val_loss: 0.6206\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6151 - val_loss: 0.6201\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6151 - val_loss: 0.6183\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6148 - val_loss: 0.6201\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6135 - val_loss: 0.6199\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6132 - val_loss: 0.6182\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6124 - val_loss: 0.6168\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6119 - val_loss: 0.6195\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6110 - val_loss: 0.6167\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6103 - val_loss: 0.6164\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6100 - val_loss: 0.6157\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.6100 - val_loss: 0.6141\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6096 - val_loss: 0.6164\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6089 - val_loss: 0.6136\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6091 - val_loss: 0.6127\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6082 - val_loss: 0.6134\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6076 - val_loss: 0.6140\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6067 - val_loss: 0.6128\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6074 - val_loss: 0.6154\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6061 - val_loss: 0.6127\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6053 - val_loss: 0.6138\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6053 - val_loss: 0.6130\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6047 - val_loss: 0.6111\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6041 - val_loss: 0.6105\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6037 - val_loss: 0.6114\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6036 - val_loss: 0.6107\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6031 - val_loss: 0.6110\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6026 - val_loss: 0.6099\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6032 - val_loss: 0.6123\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6021 - val_loss: 0.6102\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6018 - val_loss: 0.6096\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6016 - val_loss: 0.6085\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6020 - val_loss: 0.6097\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6005 - val_loss: 0.6079\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6004 - val_loss: 0.6083\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6019 - val_loss: 0.6075\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.5999 - val_loss: 0.6085\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.5995 - val_loss: 0.6071\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.5993 - val_loss: 0.6080\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.5988 - val_loss: 0.6069\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.5987 - val_loss: 0.6066\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.5991 - val_loss: 0.6071\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.5979 - val_loss: 0.6063\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.5982 - val_loss: 0.6058\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.5977 - val_loss: 0.6052\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.5977 - val_loss: 0.6055\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.5970 - val_loss: 0.6065\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.5967 - val_loss: 0.6056\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.5964 - val_loss: 0.6054\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.5963 - val_loss: 0.6053\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.5963 - val_loss: 0.6050\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.5961 - val_loss: 0.6047\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.5955 - val_loss: 0.6033\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.5951 - val_loss: 0.6050\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.5955 - val_loss: 0.6049\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.5948 - val_loss: 0.6039\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.5953 - val_loss: 0.6031\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.5941 - val_loss: 0.6035\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.5943 - val_loss: 0.6031\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.5942 - val_loss: 0.6021\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.5940 - val_loss: 0.6033\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.5934 - val_loss: 0.6037\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.5931 - val_loss: 0.6024\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.5929 - val_loss: 0.6019\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.5929 - val_loss: 0.6012\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.5927 - val_loss: 0.6022\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.6018\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.6007\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.5918 - val_loss: 0.6021\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.5923 - val_loss: 0.6006\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.5915 - val_loss: 0.6005\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.5917 - val_loss: 0.6020\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.5912 - val_loss: 0.6001\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.5916 - val_loss: 0.5994\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.5908 - val_loss: 0.5994\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.5913 - val_loss: 0.5997\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.5921 - val_loss: 0.6005\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.5902 - val_loss: 0.5991\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.5898 - val_loss: 0.6017\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.5900 - val_loss: 0.5993\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.5897 - val_loss: 0.5993\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.5898 - val_loss: 0.5978\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.5901 - val_loss: 0.5985\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.5892 - val_loss: 0.5992\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.5888 - val_loss: 0.5979\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5889 - val_loss: 0.5980\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.5883 - val_loss: 0.5978\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5889 - val_loss: 0.5972\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.5897 - val_loss: 0.5967\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5888 - val_loss: 0.5983\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5888 - val_loss: 0.5960\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.5884 - val_loss: 0.5999\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5873 - val_loss: 0.5959\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5873 - val_loss: 0.5960\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5871 - val_loss: 0.5967\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5881 - val_loss: 0.5952\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.5871 - val_loss: 0.5969\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.5865 - val_loss: 0.5955\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.5863 - val_loss: 0.5964\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.5866 - val_loss: 0.5954\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.5863 - val_loss: 0.5976\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.5862 - val_loss: 0.5954\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.5857 - val_loss: 0.5961\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.5858 - val_loss: 0.5944\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.5855 - val_loss: 0.5952\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.5855 - val_loss: 0.5954\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.5862 - val_loss: 0.5961\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.5866 - val_loss: 0.5937\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.5847 - val_loss: 0.5944\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.5850 - val_loss: 0.5937\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.5852 - val_loss: 0.5946\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.5850 - val_loss: 0.5934\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.5843 - val_loss: 0.5931\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.5841 - val_loss: 0.5932\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5850 - val_loss: 0.5947\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5848 - val_loss: 0.5922\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5842 - val_loss: 0.5935\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5839 - val_loss: 0.5937\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5832 - val_loss: 0.5930\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5832 - val_loss: 0.5923\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5835 - val_loss: 0.5915\n",
      "Retraining....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47562it [01:42, 464.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6930 - val_loss: 0.6931\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6928 - val_loss: 0.6939\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6926 - val_loss: 0.6939\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6926 - val_loss: 0.6947\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6927 - val_loss: 0.6934\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6924 - val_loss: 0.6941\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6925 - val_loss: 0.6937\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6923 - val_loss: 0.6946\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6923 - val_loss: 0.6933\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6920 - val_loss: 0.6935\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6921 - val_loss: 0.6943\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6918 - val_loss: 0.6936\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6916 - val_loss: 0.6931\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6914 - val_loss: 0.6928\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6913 - val_loss: 0.6927\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6912 - val_loss: 0.6922\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6909 - val_loss: 0.6915\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6905 - val_loss: 0.6920\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6904 - val_loss: 0.6924\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6902 - val_loss: 0.6922\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6895 - val_loss: 0.6906\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6890 - val_loss: 0.6913\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6887 - val_loss: 0.6902\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6881 - val_loss: 0.6890\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6876 - val_loss: 0.6888\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6868 - val_loss: 0.6875\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6857 - val_loss: 0.6877\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6851 - val_loss: 0.6875\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6841 - val_loss: 0.6851\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6823 - val_loss: 0.6818\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6802 - val_loss: 0.6838\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6779 - val_loss: 0.6784\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6761 - val_loss: 0.6750\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6751 - val_loss: 0.6781\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.6731 - val_loss: 0.6738\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.6716 - val_loss: 0.6739\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.6705 - val_loss: 0.6737\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.6695 - val_loss: 0.6703\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.6675 - val_loss: 0.6722\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.6663 - val_loss: 0.6688\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.6654 - val_loss: 0.6661\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.6644 - val_loss: 0.6676\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.6627 - val_loss: 0.6664\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6614 - val_loss: 0.6638\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6604 - val_loss: 0.6663\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6592 - val_loss: 0.6629\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6576 - val_loss: 0.6605\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6570 - val_loss: 0.6600\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6564 - val_loss: 0.6619\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6549 - val_loss: 0.6599\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6541 - val_loss: 0.6585\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6531 - val_loss: 0.6573\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6519 - val_loss: 0.6576\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6511 - val_loss: 0.6554\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6503 - val_loss: 0.6548\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6492 - val_loss: 0.6550\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6491 - val_loss: 0.6543\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6481 - val_loss: 0.6515\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6472 - val_loss: 0.6513\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6468 - val_loss: 0.6516\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6456 - val_loss: 0.6498\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6450 - val_loss: 0.6526\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6447 - val_loss: 0.6492\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6427 - val_loss: 0.6494\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6417 - val_loss: 0.6476\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6413 - val_loss: 0.6476\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6402 - val_loss: 0.6472\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6398 - val_loss: 0.6444\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6392 - val_loss: 0.6462\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6386 - val_loss: 0.6438\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6381 - val_loss: 0.6444\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6372 - val_loss: 0.6459\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6363 - val_loss: 0.6423\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6356 - val_loss: 0.6424\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6351 - val_loss: 0.6433\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6341 - val_loss: 0.6420\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6333 - val_loss: 0.6384\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6328 - val_loss: 0.6387\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6320 - val_loss: 0.6409\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6315 - val_loss: 0.6367\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6314 - val_loss: 0.6386\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6306 - val_loss: 0.6374\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6303 - val_loss: 0.6365\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6291 - val_loss: 0.6353\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6289 - val_loss: 0.6366\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6279 - val_loss: 0.6339\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6272 - val_loss: 0.6344\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6268 - val_loss: 0.6351\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6263 - val_loss: 0.6345\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6258 - val_loss: 0.6328\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.6248 - val_loss: 0.6327\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6245 - val_loss: 0.6316\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6239 - val_loss: 0.6306\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6235 - val_loss: 0.6320\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6231 - val_loss: 0.6286\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6226 - val_loss: 0.6291\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6230 - val_loss: 0.6298\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6217 - val_loss: 0.6285\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6211 - val_loss: 0.6282\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6202 - val_loss: 0.6272\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6198 - val_loss: 0.6274\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6193 - val_loss: 0.6270\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6191 - val_loss: 0.6268\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6182 - val_loss: 0.6254\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47562it [02:00, 396.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6182 - val_loss: 0.6241\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6172 - val_loss: 0.6250\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6168 - val_loss: 0.6259\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6170 - val_loss: 0.6261\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6158 - val_loss: 0.6229\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6157 - val_loss: 0.6222\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6155 - val_loss: 0.6239\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6147 - val_loss: 0.6224\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6141 - val_loss: 0.6226\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6144 - val_loss: 0.6224\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6138 - val_loss: 0.6222\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6131 - val_loss: 0.6205\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6128 - val_loss: 0.6199\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6119 - val_loss: 0.6213\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.6123 - val_loss: 0.6198\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.6121 - val_loss: 0.6200\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.6112 - val_loss: 0.6193\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.6111 - val_loss: 0.6192\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.6101 - val_loss: 0.6186\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.6105 - val_loss: 0.6184\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.6095 - val_loss: 0.6173\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.6094 - val_loss: 0.6189\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.6099 - val_loss: 0.6191\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.6085 - val_loss: 0.6171\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.6082 - val_loss: 0.6158\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.6084 - val_loss: 0.6177\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.6075 - val_loss: 0.6179\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.6070 - val_loss: 0.6159\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.6071 - val_loss: 0.6145\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.6065 - val_loss: 0.6153\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.6059 - val_loss: 0.6153\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6059 - val_loss: 0.6152\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.6054 - val_loss: 0.6142\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.6052 - val_loss: 0.6129\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.6049 - val_loss: 0.6138\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6050 - val_loss: 0.6124\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6045 - val_loss: 0.6122\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.6042 - val_loss: 0.6124\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.6037 - val_loss: 0.6117\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.6035 - val_loss: 0.6114\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.6041 - val_loss: 0.6114\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.6029 - val_loss: 0.6111\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.6025 - val_loss: 0.6119\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.6024 - val_loss: 0.6106\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.6025 - val_loss: 0.6124\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.6019 - val_loss: 0.6117\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.6023 - val_loss: 0.6085\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.6018 - val_loss: 0.6079\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.6005 - val_loss: 0.6113\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.6015 - val_loss: 0.6098\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.6007 - val_loss: 0.6095\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.6003 - val_loss: 0.6094\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.5999 - val_loss: 0.6091\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.6000 - val_loss: 0.6065\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.5995 - val_loss: 0.6093\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.5991 - val_loss: 0.6069\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.5990 - val_loss: 0.6086\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.5991 - val_loss: 0.6082\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.5990 - val_loss: 0.6053\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.5983 - val_loss: 0.6085\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5984 - val_loss: 0.6054\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.5983 - val_loss: 0.6066\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5986 - val_loss: 0.6072\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.5974 - val_loss: 0.6055\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5973 - val_loss: 0.6046\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5970 - val_loss: 0.6069\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.5971 - val_loss: 0.6057\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5970 - val_loss: 0.6070\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5962 - val_loss: 0.6042\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5963 - val_loss: 0.6031\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5963 - val_loss: 0.6040\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.5957 - val_loss: 0.6038\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.5961 - val_loss: 0.6044\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.5953 - val_loss: 0.6047\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.5952 - val_loss: 0.6030\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.5951 - val_loss: 0.6032\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.5953 - val_loss: 0.6044\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.5947 - val_loss: 0.6049\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.5958 - val_loss: 0.6016\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.5954 - val_loss: 0.6041\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.5940 - val_loss: 0.6018\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.5938 - val_loss: 0.6021\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.5939 - val_loss: 0.6001\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.5934 - val_loss: 0.6020\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.5935 - val_loss: 0.6012\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.5933 - val_loss: 0.5994\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.5931 - val_loss: 0.6017\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.5933 - val_loss: 0.6022\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.5927 - val_loss: 0.6003\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5930 - val_loss: 0.6022\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5930 - val_loss: 0.6000\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5923 - val_loss: 0.5996\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5918 - val_loss: 0.6003\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5928 - val_loss: 0.5986\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.5993\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5915 - val_loss: 0.5998\n",
      "Retraining....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52642it [02:17, 382.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.6931 - val_loss: 0.6928\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6930 - val_loss: 0.6927\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6930 - val_loss: 0.6927\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6929 - val_loss: 0.6927\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6926 - val_loss: 0.6920\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6924 - val_loss: 0.6923\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6923 - val_loss: 0.6924\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6922 - val_loss: 0.6928\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6919 - val_loss: 0.6918\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6917 - val_loss: 0.6918\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6914 - val_loss: 0.6911\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6909 - val_loss: 0.6915\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6906 - val_loss: 0.6906\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6901 - val_loss: 0.6900\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6895 - val_loss: 0.6904\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6888 - val_loss: 0.6890\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6880 - val_loss: 0.6884\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6872 - val_loss: 0.6874\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6864 - val_loss: 0.6861\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6852 - val_loss: 0.6866\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6838 - val_loss: 0.6838\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6826 - val_loss: 0.6825\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6802 - val_loss: 0.6811\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6775 - val_loss: 0.6764\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6745 - val_loss: 0.6715\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6696 - val_loss: 0.6692\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6668 - val_loss: 0.6694\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6652 - val_loss: 0.6664\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6635 - val_loss: 0.6660\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6616 - val_loss: 0.6628\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6604 - val_loss: 0.6653\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6594 - val_loss: 0.6627\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.6581 - val_loss: 0.6600\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.6562 - val_loss: 0.6573\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.6548 - val_loss: 0.6564\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.6539 - val_loss: 0.6566\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.6544 - val_loss: 0.6554\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.6523 - val_loss: 0.6546\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.6505 - val_loss: 0.6532\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.6495 - val_loss: 0.6521\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.6488 - val_loss: 0.6495\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6478 - val_loss: 0.6516\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6468 - val_loss: 0.6485\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6464 - val_loss: 0.6471\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6449 - val_loss: 0.6476\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6443 - val_loss: 0.6470\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6433 - val_loss: 0.6450\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6430 - val_loss: 0.6438\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6414 - val_loss: 0.6425\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6408 - val_loss: 0.6440\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6399 - val_loss: 0.6424\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "52642it [02:30, 350.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6391 - val_loss: 0.6409\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6385 - val_loss: 0.6394\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6377 - val_loss: 0.6388\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6371 - val_loss: 0.6401\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6360 - val_loss: 0.6389\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6362 - val_loss: 0.6380\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6350 - val_loss: 0.6375\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6338 - val_loss: 0.6358\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6334 - val_loss: 0.6343\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6327 - val_loss: 0.6346\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6317 - val_loss: 0.6320\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6315 - val_loss: 0.6331\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6305 - val_loss: 0.6301\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6302 - val_loss: 0.6309\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6299 - val_loss: 0.6327\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6288 - val_loss: 0.6279\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6283 - val_loss: 0.6290\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6287 - val_loss: 0.6288\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6271 - val_loss: 0.6271\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6263 - val_loss: 0.6246\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6258 - val_loss: 0.6246\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6259 - val_loss: 0.6250\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6261 - val_loss: 0.6255\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6244 - val_loss: 0.6240\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6244 - val_loss: 0.6234\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6244 - val_loss: 0.6235\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6233 - val_loss: 0.6219\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6236 - val_loss: 0.6214\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6224 - val_loss: 0.6212\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6214 - val_loss: 0.6219\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6211 - val_loss: 0.6206\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6203 - val_loss: 0.6203\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6193 - val_loss: 0.6177\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6192 - val_loss: 0.6167\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6193 - val_loss: 0.6184\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6187 - val_loss: 0.6204\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6177 - val_loss: 0.6152\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.6177 - val_loss: 0.6143\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6172 - val_loss: 0.6151\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6165 - val_loss: 0.6161\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6166 - val_loss: 0.6157\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6160 - val_loss: 0.6133\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6157 - val_loss: 0.6119\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6150 - val_loss: 0.6133\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6149 - val_loss: 0.6134\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6139 - val_loss: 0.6122\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6138 - val_loss: 0.6096\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6133 - val_loss: 0.6105\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6129 - val_loss: 0.6090\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6138 - val_loss: 0.6127\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6128 - val_loss: 0.6080\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6128 - val_loss: 0.6142\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6110 - val_loss: 0.6060\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6111 - val_loss: 0.6071\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6111 - val_loss: 0.6049\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6107 - val_loss: 0.6052\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6098 - val_loss: 0.6073\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6098 - val_loss: 0.6047\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6093 - val_loss: 0.6039\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6090 - val_loss: 0.6039\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6088 - val_loss: 0.6032\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6086 - val_loss: 0.6021\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6080 - val_loss: 0.6028\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6081 - val_loss: 0.6008\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6073 - val_loss: 0.6033\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.6073 - val_loss: 0.6014\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.6067 - val_loss: 0.6027\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.6067 - val_loss: 0.6044\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.6070 - val_loss: 0.6001\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.6059 - val_loss: 0.6030\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.6057 - val_loss: 0.5990\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.6052 - val_loss: 0.6005\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.6048 - val_loss: 0.5992\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.6046 - val_loss: 0.5994\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.6046 - val_loss: 0.5976\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.6051 - val_loss: 0.5965\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.6036 - val_loss: 0.5992\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.6038 - val_loss: 0.5976\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.6032 - val_loss: 0.5972\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.6034 - val_loss: 0.5981\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.6027 - val_loss: 0.5974\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.6031 - val_loss: 0.5958\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6024 - val_loss: 0.5976\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.6018 - val_loss: 0.5960\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.6022 - val_loss: 0.5955\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.6022 - val_loss: 0.5960\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6012 - val_loss: 0.5936\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6009 - val_loss: 0.5957\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.6012 - val_loss: 0.5936\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.6008 - val_loss: 0.5953\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.6008 - val_loss: 0.5937\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.6000 - val_loss: 0.5944\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.5998 - val_loss: 0.5935\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.5994 - val_loss: 0.5934\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.5992 - val_loss: 0.5920\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.5997 - val_loss: 0.5937\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.5988 - val_loss: 0.5924\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.5994 - val_loss: 0.5912\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.5989 - val_loss: 0.5914\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.5984 - val_loss: 0.5909\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.5979 - val_loss: 0.5907\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.5980 - val_loss: 0.5899\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.5975 - val_loss: 0.5917\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.5984 - val_loss: 0.5896\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.5974 - val_loss: 0.5905\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.5967 - val_loss: 0.5903\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.5977 - val_loss: 0.5901\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.5968 - val_loss: 0.5894\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.5962 - val_loss: 0.5912\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.5965 - val_loss: 0.5905\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.5964 - val_loss: 0.5907\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5956 - val_loss: 0.5884\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.5962 - val_loss: 0.5880\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5953 - val_loss: 0.5877\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.5952 - val_loss: 0.5879\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5946 - val_loss: 0.5883\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5945 - val_loss: 0.5873\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.5948 - val_loss: 0.5860\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5947 - val_loss: 0.5871\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5941 - val_loss: 0.5856\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5937 - val_loss: 0.5874\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5938 - val_loss: 0.5866\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.5933 - val_loss: 0.5858\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.5934 - val_loss: 0.5858\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.5930 - val_loss: 0.5869\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.5926 - val_loss: 0.5845\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.5931 - val_loss: 0.5864\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.5939 - val_loss: 0.5836\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.5880\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.5922 - val_loss: 0.5843\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.5923 - val_loss: 0.5830\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.5935 - val_loss: 0.5834\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.5917 - val_loss: 0.5841\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.5915 - val_loss: 0.5855\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.5910 - val_loss: 0.5840\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.5910 - val_loss: 0.5835\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.5909 - val_loss: 0.5841\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.5909 - val_loss: 0.5845\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.5910 - val_loss: 0.5845\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.5905 - val_loss: 0.5841\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5900 - val_loss: 0.5825\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5903 - val_loss: 0.5819\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5903 - val_loss: 0.5848\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5899 - val_loss: 0.5825\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5897 - val_loss: 0.5823\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5896 - val_loss: 0.5823\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5889 - val_loss: 0.5804\n",
      "Retraining....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57256it [03:00, 317.73it/s]\n"
     ]
    }
   ],
   "source": [
    "def backtest(is_retrain, volume, sl, tp):\n",
    "    backtest_params = {\n",
    "        \"is_retrain\": \"always\" if(is_retrain) else \"once\",\n",
    "        \"volume\":volume,\n",
    "        \"sl\":sl,\n",
    "        \"tp\":tp\n",
    "    }\n",
    "    \n",
    "    # currency_pairs = ['USDJPY', 'AUDUSD', 'EURUSD', 'GBPUSD', 'NZDUSD', 'USDCAD', 'USDCHF']\n",
    "\n",
    "    num_step = 10\n",
    "    skip_step = 1\n",
    "    test_range_limit = 200\n",
    "\n",
    "\n",
    "    currency_pair = 'EURJPY'\n",
    "\n",
    "    file_path = \"oneshot_dataset/\"+currency_pair+\"_H1_200910290000_201901252300.csv\"\n",
    "    testing_hourly = pd.read_csv(file_path, sep='\\t')\n",
    "    if (\"JPY\" in file_path):\n",
    "        testing_hourly['<OPEN>'] = testing_hourly['<OPEN>']/100\n",
    "        testing_hourly['<HIGH>'] = testing_hourly['<HIGH>']/100\n",
    "        testing_hourly['<LOW>'] = testing_hourly['<LOW>']/100\n",
    "        testing_hourly['<CLOSE>'] = testing_hourly['<CLOSE>']/100\n",
    "\n",
    "    graph = evaluate(testing_hourly, create_model(), backtest_params)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph = backtest(True, 1, 400, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2568.4000000000215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fc98b7c88>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(graph[-1][\"balance_history\"])\n",
    "balance_hist = []\n",
    "for i in graph:\n",
    "    balance_hist.append(i[\"balance_history\"])\n",
    "plt.plot(balance_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
